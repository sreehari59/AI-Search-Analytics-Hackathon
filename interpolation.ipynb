{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9e3838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the unified training data system\n",
    "from unifiedTrainingData import (\n",
    "    createUnifiedTrainingData, \n",
    "    loadUnifiedTrainingData, \n",
    "    getUnifiedTrainingDataStats,\n",
    "    prepareUnifiedTrainingDataForModel\n",
    ")\n",
    "\n",
    "# Define your keywords\n",
    "keywords = [\n",
    "    'tesla', 'bmw', 'mercedes', 'audi', 'volkswagen', 'toyota', 'honda', 'ford', \n",
    "    'chevrolet', 'hyundai', 'kia', 'nissan', 'volvo', 'lexus', 'porsche', \n",
    "    'electric car', 'ev', 'electric vehicle', 'hybrid car', 'autonomous car',\n",
    "    'self driving car', 'car sharing', 'ride sharing', 'uber', 'lyft',\n",
    "    'car rental', 'car insurance', 'car maintenance', 'car repair',\n",
    "    'car dealership', 'car financing', 'car loan', 'car lease'\n",
    "]\n",
    "\n",
    "# print(f\"Creating unified training data for {len(keywords)} car and EV keywords...\")\n",
    "# print(\"This will save embeddings, ChatGPT trends, and Google Trends in a single JSON file.\")\n",
    "# print(\"Note: If Google Trends API fails, random realistic trends will be generated.\")\n",
    "# print(\"=\"*70)\n",
    "\n",
    "# Create unified training data\n",
    "summary = createUnifiedTrainingData(\n",
    "    keywords=keywords,\n",
    "    startDate=\"2025-06-01\",\n",
    "    endDate=\"2025-06-30\",\n",
    "    model='text-embedding-ada-002',\n",
    "    filename='data/unified_training_data.json'\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ Training data creation completed!\")\n",
    "print(f\"Success rate: {summary['success_rate']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd726e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and verify the created training data\n",
    "print(\"\\nVerifying created training data...\")\n",
    "data = loadUnifiedTrainingData()\n",
    "\n",
    "print(f\"Total keywords in training data: {len(data)}\")\n",
    "\n",
    "# Show sample data structure\n",
    "if data:\n",
    "    sample_keyword = list(data.keys())[0]\n",
    "    embedding, chatgpt_trend, google_trend = data[sample_keyword]\n",
    "    print(f\"\\nSample data for '{sample_keyword}':\")\n",
    "    print(f\"  Embedding shape: {embedding.shape}\")\n",
    "    print(f\"  ChatGPT trend shape: {chatgpt_trend.shape}\")\n",
    "    print(f\"  Google trend shape: {google_trend.shape}\")\n",
    "    print(f\"  Google trend sample: {google_trend[:5]}\")\n",
    "    print(f\"  ChatGPT trend sample: {chatgpt_trend[:5]}\")\n",
    "\n",
    "# Prepare data for the embedding KNN model\n",
    "print(f\"\\nPreparing data for embedding KNN model...\")\n",
    "prepareUnifiedTrainingDataForModel(data)\n",
    "print(f\"✅ Data prepared for model use!\")\n",
    "\n",
    "# Show final statistics\n",
    "stats = getUnifiedTrainingDataStats()\n",
    "print(f\"\\nFinal training data statistics:\")\n",
    "print(f\"  Total keywords: {stats['total_keywords']}\")\n",
    "print(f\"  File size: {stats['file_size_mb']:.2f} MB\")\n",
    "print(f\"  Keywords: {stats['keywords'][:10]}...\")  # Show first 10 keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd8e8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test inference with the trained model\n",
    "from embeddingsKNN import quickKeywordAnalysis, analyzeNewKeyword\n",
    "\n",
    "# Test keywords\n",
    "test_keywords = ['tesla model 3', 'bmw i4', 'hyundai ioniq']\n",
    "\n",
    "print(\"Testing inference with trained model...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for keyword in test_keywords:\n",
    "    print(f\"\\nTesting: {keyword}\")\n",
    "    try:\n",
    "        # Quick analysis\n",
    "        result = quickKeywordAnalysis(keyword, \"2025-06-01\", \"2025-06-30\")\n",
    "        print(f\"  Google trend mean: {result['google_trend_mean']:.1f}\")\n",
    "        print(f\"  Predicted ChatGPT mean: {result['predicted_chatgpt_mean']:.1f}\")\n",
    "        print(f\"  Prediction confidence: {result['prediction_confidence']:.3f}\")\n",
    "        print(f\"  Nearest neighbors: {result['nearest_neighbors']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c98375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from embeddingsKNN import quickKeywordAnalysis, analyzeNewKeyword\n",
    "from unifiedTrainingData import loadUnifiedTrainingData, prepareUnifiedTrainingDataForModel\n",
    "\n",
    "# Load and prepare the training data for the model\n",
    "print(\"Loading unified training data...\")\n",
    "data = loadUnifiedTrainingData()\n",
    "prepareUnifiedTrainingDataForModel(data)\n",
    "print(f\"✅ Model prepared with {len(data)} keywords\")\n",
    "\n",
    "# Test keywords for plotting\n",
    "test_keywords = ['tesla model 3', 'bmw i4', 'hyundai ioniq', 'electric suv', 'autonomous driving']\n",
    "\n",
    "# Create comprehensive plots\n",
    "fig, axes = plt.subplots(len(test_keywords), 2, figsize=(15, 5*len(test_keywords)))\n",
    "if len(test_keywords) == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "print(f\"Analyzing and plotting results for {len(test_keywords)} keywords...\")\n",
    "\n",
    "for i, keyword in enumerate(test_keywords):\n",
    "    print(f\"Processing {i+1}/{len(test_keywords)}: {keyword}\")\n",
    "    \n",
    "    try:\n",
    "        # Get detailed analysis\n",
    "        result = analyzeNewKeyword(keyword, \"2025-06-01\", \"2025-06-30\")\n",
    "        \n",
    "        # Extract data\n",
    "        google_trends = result['google_trends']['trend_values']\n",
    "        predicted_chatgpt = result['predicted_chatgpt_trend']['trend_values']\n",
    "        actual_chatgpt = result['actual_chatgpt_trend']['trend_values']\n",
    "        dates = pd.date_range(\"2025-06-01\", \"2025-06-30\", freq='D')\n",
    "        \n",
    "        # Plot 1: Google Trends vs Predicted ChatGPT Trends\n",
    "        ax1 = axes[i, 0]\n",
    "        ax1.plot(dates, google_trends, 'b-', label='Google Trends', linewidth=2, alpha=0.8)\n",
    "        ax1.plot(dates, predicted_chatgpt, 'r--', label='Predicted ChatGPT', linewidth=2, alpha=0.8)\n",
    "        ax1.plot(dates, actual_chatgpt, 'g-', label='Actual ChatGPT', linewidth=2, alpha=0.8)\n",
    "        ax1.set_title(f'Trend Comparison: {keyword}', fontsize=14, fontweight='bold')\n",
    "        ax1.set_ylabel('Trend Value', fontsize=12)\n",
    "        ax1.legend(fontsize=10)\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add correlation info\n",
    "        correlation = np.corrcoef(google_trends, predicted_chatgpt)[0, 1]\n",
    "        ax1.text(0.02, 0.98, f'Correlation: {correlation:.3f}', \n",
    "                transform=ax1.transAxes, fontsize=10, \n",
    "                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "        \n",
    "        # Plot 2: Neighbor Similarities\n",
    "        ax2 = axes[i, 1]\n",
    "        neighbors = result['neighbors']\n",
    "        neighbor_names = [n['keyword'] for n in neighbors]\n",
    "        similarities = [n['similarity'] for n in neighbors]\n",
    "        \n",
    "        bars = ax2.bar(neighbor_names, similarities, color='skyblue', alpha=0.7)\n",
    "        ax2.set_title(f'Nearest Neighbors: {keyword}', fontsize=14, fontweight='bold')\n",
    "        ax2.set_ylabel('Similarity Score', fontsize=12)\n",
    "        ax2.set_ylim(0, 1)\n",
    "        \n",
    "        # Add similarity values on bars\n",
    "        for bar, similarity in zip(bars, similarities):\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                    f'{similarity:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add prediction confidence\n",
    "        confidence = result['analysis_summary']['prediction_confidence']\n",
    "        ax2.text(0.02, 0.98, f'Confidence: {confidence:.3f}', \n",
    "                transform=ax2.transAxes, fontsize=10, \n",
    "                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing '{keyword}': {e}\")\n",
    "        # Create empty plots for failed keywords\n",
    "        axes[i, 0].text(0.5, 0.5, f'Error: {str(e)[:50]}...', \n",
    "                       ha='center', va='center', transform=axes[i, 0].transAxes,\n",
    "                       bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.8))\n",
    "        axes[i, 0].set_title(f'Error: {keyword}', fontsize=14, fontweight='bold')\n",
    "        axes[i, 1].text(0.5, 0.5, 'No data available', \n",
    "                       ha='center', va='center', transform=axes[i, 1].transAxes)\n",
    "        axes[i, 1].set_title(f'No neighbors: {keyword}', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "summary_data = []\n",
    "for keyword in test_keywords:\n",
    "    try:\n",
    "        result = quickKeywordAnalysis(keyword, \"2025-06-01\", \"2025-06-30\")\n",
    "        summary_data.append({\n",
    "            'Keyword': keyword,\n",
    "            'Google Trend Mean': f\"{result['google_trend_mean']:.1f}\",\n",
    "            'Predicted ChatGPT Mean': f\"{result['predicted_chatgpt_mean']:.1f}\",\n",
    "            'Prediction Confidence': f\"{result['prediction_confidence']:.3f}\",\n",
    "            'Trend Magnitude': result['trend_magnitude'],\n",
    "            'Volatility Level': result['volatility_level'],\n",
    "            'Nearest Neighbors': ', '.join(result['nearest_neighbors'][:3])\n",
    "        })\n",
    "    except Exception as e:\n",
    "        summary_data.append({\n",
    "            'Keyword': keyword,\n",
    "            'Google Trend Mean': 'Error',\n",
    "            'Predicted ChatGPT Mean': 'Error',\n",
    "            'Prediction Confidence': 'Error',\n",
    "            'Trend Magnitude': 'Error',\n",
    "            'Volatility Level': 'Error',\n",
    "            'Nearest Neighbors': 'Error'\n",
    "        })\n",
    "\n",
    "# Create summary table\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Additional detailed analysis plot\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"DETAILED ANALYSIS PLOT\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Create a single comprehensive plot for one keyword\n",
    "if test_keywords:\n",
    "    keyword = test_keywords[0]  # Use first keyword for detailed analysis\n",
    "    try:\n",
    "        result = analyzeNewKeyword(keyword, \"2025-06-01\", \"2025-06-30\")\n",
    "        \n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        \n",
    "        dates = pd.date_range(\"2025-06-01\", \"2025-06-30\", freq='D')\n",
    "        google_trends = result['google_trends']['trend_values']\n",
    "        predicted_chatgpt = result['predicted_chatgpt_trend']['trend_values']\n",
    "        actual_chatgpt = result['actual_chatgpt_trend']['trend_values']\n",
    "        \n",
    "        # Plot 1: All trends together\n",
    "        ax1.plot(dates, google_trends, 'b-', label='Google Trends', linewidth=2)\n",
    "        ax1.plot(dates, predicted_chatgpt, 'r--', label='Predicted ChatGPT', linewidth=2)\n",
    "        ax1.plot(dates, actual_chatgpt, 'g-', label='Actual ChatGPT', linewidth=2)\n",
    "        ax1.set_title(f'Complete Trend Analysis: {keyword}', fontsize=14, fontweight='bold')\n",
    "        ax1.set_ylabel('Trend Value')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Plot 2: Prediction accuracy\n",
    "        ax2.scatter(actual_chatgpt, predicted_chatgpt, alpha=0.6, color='purple')\n",
    "        ax2.plot([0, 100], [0, 100], 'r--', alpha=0.5, label='Perfect Prediction')\n",
    "        ax2.set_xlabel('Actual ChatGPT Trend')\n",
    "        ax2.set_ylabel('Predicted ChatGPT Trend')\n",
    "        ax2.set_title('Prediction Accuracy', fontsize=14, fontweight='bold')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 3: Trend correlation\n",
    "        ax3.plot(dates, google_trends, 'b-', label='Google Trends', alpha=0.7)\n",
    "        ax3.plot(dates, predicted_chatgpt, 'r-', label='Predicted ChatGPT', alpha=0.7)\n",
    "        ax3.set_xlabel('Date')\n",
    "        ax3.set_ylabel('Trend Value')\n",
    "        ax3.set_title('Google vs Predicted ChatGPT Correlation', fontsize=14, fontweight='bold')\n",
    "        ax3.legend()\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        ax3.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Plot 4: Neighbor similarities\n",
    "        neighbors = result['neighbors']\n",
    "        neighbor_names = [n['keyword'] for n in neighbors]\n",
    "        similarities = [n['similarity'] for n in neighbors]\n",
    "        \n",
    "        bars = ax4.bar(neighbor_names, similarities, color='orange', alpha=0.7)\n",
    "        ax4.set_title('Nearest Neighbors Similarity', fontsize=14, fontweight='bold')\n",
    "        ax4.set_ylabel('Similarity Score')\n",
    "        ax4.set_ylim(0, 1)\n",
    "        ax4.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add values on bars\n",
    "        for bar, similarity in zip(bars, similarities):\n",
    "            ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                    f'{similarity:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print detailed metrics\n",
    "        print(f\"\\nDetailed Metrics for '{keyword}':\")\n",
    "        print(f\"  MSE: {result['prediction_metrics']['mse']:.4f}\")\n",
    "        print(f\"  MAE: {result['prediction_metrics']['mae']:.4f}\")\n",
    "        print(f\"  RMSE: {result['prediction_metrics']['rmse']:.4f}\")\n",
    "        print(f\"  Correlation: {result['analysis_summary']['trend_correlation']:.4f}\")\n",
    "        print(f\"  Confidence: {result['analysis_summary']['prediction_confidence']:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in detailed analysis for '{keyword}': {e}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ANALYSIS COMPLETED\")\n",
    "print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peec-hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
