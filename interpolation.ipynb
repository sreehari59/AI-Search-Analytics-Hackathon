{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9e3838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the unified training data system\n",
    "from unifiedTrainingData import (\n",
    "    createUnifiedTrainingData, \n",
    "    loadUnifiedTrainingData, \n",
    "    getUnifiedTrainingDataStats,\n",
    "    prepareUnifiedTrainingDataForModel\n",
    ")\n",
    "\n",
    "# Define your keywords\n",
    "keywords = [\n",
    "    'tesla', 'bmw', 'mercedes', 'audi', 'volkswagen', 'toyota', 'honda', 'ford', \n",
    "    'chevrolet', 'hyundai', 'kia', 'nissan', 'volvo', 'lexus', 'porsche', \n",
    "    'electric car', 'ev', 'electric vehicle', 'hybrid car', 'autonomous car',\n",
    "    'self driving car', 'car sharing', 'ride sharing', 'uber', 'lyft',\n",
    "    'car rental', 'car insurance', 'car maintenance', 'car repair',\n",
    "    'car dealership', 'car financing', 'car loan', 'car lease'\n",
    "]\n",
    "\n",
    "# Create unified training data\n",
    "summary = createUnifiedTrainingData(\n",
    "    keywords=keywords,\n",
    "    startDate=\"2025-06-01\",\n",
    "    endDate=\"2025-06-30\",\n",
    "    model='text-embedding-ada-002',\n",
    "    filename='data/unified_training_data.json'\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ Training data creation completed!\")\n",
    "print(f\"Success rate: {summary['success_rate']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd726e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and verify the created training data\n",
    "print(\"\\nVerifying created training data...\")\n",
    "data = loadUnifiedTrainingData()\n",
    "\n",
    "print(f\"Total keywords in training data: {len(data)}\")\n",
    "\n",
    "# Show sample data structure\n",
    "if data:\n",
    "    sample_keyword = list(data.keys())[0]\n",
    "    embedding, chatgpt_trend, google_trend = data[sample_keyword]\n",
    "    print(f\"\\nSample data for '{sample_keyword}':\")\n",
    "    print(f\"  Embedding shape: {embedding.shape}\")\n",
    "    print(f\"  ChatGPT trend shape: {chatgpt_trend.shape}\")\n",
    "    print(f\"  Google trend shape: {google_trend.shape}\")\n",
    "    print(f\"  Google trend sample: {google_trend[:5]}\")\n",
    "    print(f\"  ChatGPT trend sample: {chatgpt_trend[:5]}\")\n",
    "\n",
    "# Prepare data for the embedding KNN model\n",
    "print(f\"\\nPreparing data for embedding KNN model...\")\n",
    "prepareUnifiedTrainingDataForModel(data)\n",
    "print(f\"✅ Data prepared for model use!\")\n",
    "\n",
    "# Show final statistics\n",
    "stats = getUnifiedTrainingDataStats()\n",
    "print(f\"\\nFinal training data statistics:\")\n",
    "print(f\"  Total keywords: {stats['total_keywords']}\")\n",
    "print(f\"  File size: {stats['file_size_mb']:.2f} MB\")\n",
    "print(f\"  Keywords: {stats['keywords'][:10]}...\")  # Show first 10 keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd8e8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test inference with the trained model\n",
    "from embeddingsKNN import quickKeywordAnalysis, analyzeNewKeyword\n",
    "\n",
    "# Test keywords\n",
    "test_keywords = ['tesla model 3', 'bmw i4', 'hyundai ioniq']\n",
    "\n",
    "print(\"Testing inference with trained model...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for keyword in test_keywords:\n",
    "    print(f\"\\nTesting: {keyword}\")\n",
    "    try:\n",
    "        # Quick analysis\n",
    "        result = quickKeywordAnalysis(keyword, \"2025-06-01\", \"2025-06-30\")\n",
    "        print(f\"  Google trend mean: {result['google_trend_mean']:.1f}\")\n",
    "        print(f\"  Predicted ChatGPT mean: {result['predicted_chatgpt_mean']:.1f}\")\n",
    "        print(f\"  Prediction confidence: {result['prediction_confidence']:.3f}\")\n",
    "        print(f\"  Nearest neighbors: {result['nearest_neighbors']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c98375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from embeddingsKNN import quickKeywordAnalysis, analyzeNewKeyword\n",
    "from unifiedTrainingData import loadUnifiedTrainingData, prepareUnifiedTrainingDataForModel\n",
    "\n",
    "# Load and prepare the training data for the model\n",
    "print(\"Loading unified training data...\")\n",
    "data = loadUnifiedTrainingData()\n",
    "prepareUnifiedTrainingDataForModel(data)\n",
    "print(f\"✅ Model prepared with {len(data)} keywords\")\n",
    "\n",
    "# Test keywords for plotting\n",
    "test_keywords = ['tesla model 3', 'bmw i4', 'hyundai ioniq', 'electric suv', 'autonomous driving']\n",
    "\n",
    "# Create comprehensive plots\n",
    "fig, axes = plt.subplots(len(test_keywords), 2, figsize=(15, 5*len(test_keywords)))\n",
    "if len(test_keywords) == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "print(f\"Analyzing and plotting results for {len(test_keywords)} keywords...\")\n",
    "\n",
    "for i, keyword in enumerate(test_keywords):\n",
    "    print(f\"Processing {i+1}/{len(test_keywords)}: {keyword}\")\n",
    "    \n",
    "    try:\n",
    "        # Get detailed analysis\n",
    "        result = analyzeNewKeyword(keyword, \"2025-06-01\", \"2025-06-30\")\n",
    "        \n",
    "        # Extract data\n",
    "        google_trends = result['google_trends']['trend_values']\n",
    "        predicted_chatgpt = result['predicted_chatgpt_trend']['trend_values']\n",
    "        actual_chatgpt = result['actual_chatgpt_trend']['trend_values']\n",
    "        dates = pd.date_range(\"2025-06-01\", \"2025-06-30\", freq='D')\n",
    "        \n",
    "        # Plot 1: Google Trends vs Predicted ChatGPT Trends\n",
    "        ax1 = axes[i, 0]\n",
    "        ax1.plot(dates, google_trends, 'b-', label='Google Trends', linewidth=2, alpha=0.8)\n",
    "        ax1.plot(dates, predicted_chatgpt, 'r--', label='Predicted ChatGPT', linewidth=2, alpha=0.8)\n",
    "        ax1.plot(dates, actual_chatgpt, 'g-', label='Actual ChatGPT', linewidth=2, alpha=0.8)\n",
    "        ax1.set_title(f'Trend Comparison: {keyword}', fontsize=14, fontweight='bold')\n",
    "        ax1.set_ylabel('Trend Value', fontsize=12)\n",
    "        ax1.legend(fontsize=10)\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add correlation info\n",
    "        correlation = np.corrcoef(google_trends, predicted_chatgpt)[0, 1]\n",
    "        ax1.text(0.02, 0.98, f'Correlation: {correlation:.3f}', \n",
    "                transform=ax1.transAxes, fontsize=10, \n",
    "                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "        \n",
    "        # Plot 2: Neighbor Similarities\n",
    "        ax2 = axes[i, 1]\n",
    "        neighbors = result['neighbors']\n",
    "        neighbor_names = [n['keyword'] for n in neighbors]\n",
    "        similarities = [n['similarity'] for n in neighbors]\n",
    "        \n",
    "        bars = ax2.bar(neighbor_names, similarities, color='skyblue', alpha=0.7)\n",
    "        ax2.set_title(f'Nearest Neighbors: {keyword}', fontsize=14, fontweight='bold')\n",
    "        ax2.set_ylabel('Similarity Score', fontsize=12)\n",
    "        ax2.set_ylim(0, 1)\n",
    "        \n",
    "        # Add similarity values on bars\n",
    "        for bar, similarity in zip(bars, similarities):\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                    f'{similarity:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add prediction confidence\n",
    "        confidence = result['analysis_summary']['prediction_confidence']\n",
    "        ax2.text(0.02, 0.98, f'Confidence: {confidence:.3f}', \n",
    "                transform=ax2.transAxes, fontsize=10, \n",
    "                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing '{keyword}': {e}\")\n",
    "        # Create empty plots for failed keywords\n",
    "        axes[i, 0].text(0.5, 0.5, f'Error: {str(e)[:50]}...', \n",
    "                       ha='center', va='center', transform=axes[i, 0].transAxes,\n",
    "                       bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.8))\n",
    "        axes[i, 0].set_title(f'Error: {keyword}', fontsize=14, fontweight='bold')\n",
    "        axes[i, 1].text(0.5, 0.5, 'No data available', \n",
    "                       ha='center', va='center', transform=axes[i, 1].transAxes)\n",
    "        axes[i, 1].set_title(f'No neighbors: {keyword}', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "summary_data = []\n",
    "for keyword in test_keywords:\n",
    "    try:\n",
    "        result = quickKeywordAnalysis(keyword, \"2025-06-01\", \"2025-06-30\")\n",
    "        summary_data.append({\n",
    "            'Keyword': keyword,\n",
    "            'Google Trend Mean': f\"{result['google_trend_mean']:.1f}\",\n",
    "            'Predicted ChatGPT Mean': f\"{result['predicted_chatgpt_mean']:.1f}\",\n",
    "            'Prediction Confidence': f\"{result['prediction_confidence']:.3f}\",\n",
    "            'Trend Magnitude': result['trend_magnitude'],\n",
    "            'Volatility Level': result['volatility_level'],\n",
    "            'Nearest Neighbors': ', '.join(result['nearest_neighbors'][:3])\n",
    "        })\n",
    "    except Exception as e:\n",
    "        summary_data.append({\n",
    "            'Keyword': keyword,\n",
    "            'Google Trend Mean': 'Error',\n",
    "            'Predicted ChatGPT Mean': 'Error',\n",
    "            'Prediction Confidence': 'Error',\n",
    "            'Trend Magnitude': 'Error',\n",
    "            'Volatility Level': 'Error',\n",
    "            'Nearest Neighbors': 'Error'\n",
    "        })\n",
    "\n",
    "# Create summary table\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Additional detailed analysis plot\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"DETAILED ANALYSIS PLOT\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Create a single comprehensive plot for one keyword\n",
    "if test_keywords:\n",
    "    keyword = test_keywords[0]  # Use first keyword for detailed analysis\n",
    "    try:\n",
    "        result = analyzeNewKeyword(keyword, \"2025-06-01\", \"2025-06-30\")\n",
    "        \n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        \n",
    "        dates = pd.date_range(\"2025-06-01\", \"2025-06-30\", freq='D')\n",
    "        google_trends = result['google_trends']['trend_values']\n",
    "        predicted_chatgpt = result['predicted_chatgpt_trend']['trend_values']\n",
    "        actual_chatgpt = result['actual_chatgpt_trend']['trend_values']\n",
    "        \n",
    "        # Plot 1: All trends together\n",
    "        ax1.plot(dates, google_trends, 'b-', label='Google Trends', linewidth=2)\n",
    "        ax1.plot(dates, predicted_chatgpt, 'r--', label='Predicted ChatGPT', linewidth=2)\n",
    "        ax1.plot(dates, actual_chatgpt, 'g-', label='Actual ChatGPT', linewidth=2)\n",
    "        ax1.set_title(f'Complete Trend Analysis: {keyword}', fontsize=14, fontweight='bold')\n",
    "        ax1.set_ylabel('Trend Value')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Plot 2: Prediction accuracy\n",
    "        ax2.scatter(actual_chatgpt, predicted_chatgpt, alpha=0.6, color='purple')\n",
    "        ax2.plot([0, 100], [0, 100], 'r--', alpha=0.5, label='Perfect Prediction')\n",
    "        ax2.set_xlabel('Actual ChatGPT Trend')\n",
    "        ax2.set_ylabel('Predicted ChatGPT Trend')\n",
    "        ax2.set_title('Prediction Accuracy', fontsize=14, fontweight='bold')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 3: Trend correlation\n",
    "        ax3.plot(dates, google_trends, 'b-', label='Google Trends', alpha=0.7)\n",
    "        ax3.plot(dates, predicted_chatgpt, 'r-', label='Predicted ChatGPT', alpha=0.7)\n",
    "        ax3.set_xlabel('Date')\n",
    "        ax3.set_ylabel('Trend Value')\n",
    "        ax3.set_title('Google vs Predicted ChatGPT Correlation', fontsize=14, fontweight='bold')\n",
    "        ax3.legend()\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        ax3.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Plot 4: Neighbor similarities\n",
    "        neighbors = result['neighbors']\n",
    "        neighbor_names = [n['keyword'] for n in neighbors]\n",
    "        similarities = [n['similarity'] for n in neighbors]\n",
    "        \n",
    "        bars = ax4.bar(neighbor_names, similarities, color='orange', alpha=0.7)\n",
    "        ax4.set_title('Nearest Neighbors Similarity', fontsize=14, fontweight='bold')\n",
    "        ax4.set_ylabel('Similarity Score')\n",
    "        ax4.set_ylim(0, 1)\n",
    "        ax4.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add values on bars\n",
    "        for bar, similarity in zip(bars, similarities):\n",
    "            ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                    f'{similarity:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print detailed metrics\n",
    "        print(f\"\\nDetailed Metrics for '{keyword}':\")\n",
    "        print(f\"  MSE: {result['prediction_metrics']['mse']:.4f}\")\n",
    "        print(f\"  MAE: {result['prediction_metrics']['mae']:.4f}\")\n",
    "        print(f\"  RMSE: {result['prediction_metrics']['rmse']:.4f}\")\n",
    "        print(f\"  Correlation: {result['analysis_summary']['trend_correlation']:.4f}\")\n",
    "        print(f\"  Confidence: {result['analysis_summary']['prediction_confidence']:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in detailed analysis for '{keyword}': {e}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ANALYSIS COMPLETED\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0575e763",
   "metadata": {},
   "source": [
    "# Prompt Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf5fda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required functions\n",
    "from embeddingsKNN import promptToKeywordsAndAnalyze, loadTrainingData\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load training data\n",
    "print(\"🔄 Loading training data...\")\n",
    "loadTrainingData()\n",
    "print(\"✅ Training data loaded successfully\")\n",
    "\n",
    "# Run inference on the prompt\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"🚀 RUNNING INFERENCE ON PROMPT: 'is the model 3 a good car?'\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Execute the analysis\n",
    "result = promptToKeywordsAndAnalyze(\n",
    "    prompt=\"is the model 3 a good car?\",\n",
    "    startDate=\"2025-06-01\",\n",
    "    endDate=\"2025-06-30\",\n",
    "    k=3,\n",
    "    weights='distance'\n",
    ")\n",
    "\n",
    "print(f\"\\n Analysis completed!\")\n",
    "print(f\"📝 Original prompt: '{result['prompt']}'\")\n",
    "print(f\" Generated keywords: {result['generated_keywords']}\")\n",
    "print(f\"✅ Successfully analyzed: {result['successful_keywords']}\")\n",
    "print(f\" Keywords processed: {result['average_result']['num_keywords']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7315fff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display detailed results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"📈 DETAILED ANALYSIS RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Show individual keyword performance\n",
    "for i, keyword in enumerate(result['successful_keywords']):\n",
    "    individual = result['individual_results'][i]\n",
    "    print(f\"\\n🔍 Keyword {i+1}: '{keyword}'\")\n",
    "    print(f\"   Google Trend Mean: {individual['google_trends']['statistics']['mean_trend']:.1f}\")\n",
    "    print(f\"   🤖 Predicted ChatGPT Mean: {individual['predicted_chatgpt_trend']['statistics']['mean_predicted']:.1f}\")\n",
    "    print(f\"   🎯 Prediction Confidence: {individual['analysis_summary']['prediction_confidence']:.3f}\")\n",
    "    print(f\"   Trend Correlation: {individual['analysis_summary']['trend_correlation']:.3f}\")\n",
    "    print(f\"   👥 Similar Keywords: {[n['keyword'] for n in individual['neighbors']]}\")\n",
    "\n",
    "# Show aggregated results\n",
    "avg = result['average_result']\n",
    "print(f\"\\n AGGREGATED RESULTS (Average of {avg['num_keywords']} keywords):\")\n",
    "print(f\"   📈 Average Google Trend: {avg['average_google_trend']:.2f} ± {avg['std_google_trend']:.2f}\")\n",
    "print(f\"   🤖 Average Predicted ChatGPT: {avg['average_predicted_chatgpt']:.2f} ± {avg['std_predicted_chatgpt']:.2f}\")\n",
    "print(f\"   Average Confidence: {avg['average_confidence']:.3f} ± {avg['std_confidence']:.3f}\")\n",
    "print(f\"   📊 Average Correlation: {avg['average_correlation']:.3f} ± {avg['std_correlation']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3bc8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create additional custom visualizations\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"📊 CUSTOM VISUALIZATION ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Extract data for custom plots\n",
    "keywords = result['successful_keywords']\n",
    "individual_results = result['individual_results']\n",
    "\n",
    "# Create a comprehensive analysis plot\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(18, 14))\n",
    "\n",
    "# Plot 1: Performance comparison\n",
    "google_means = [r['google_trends']['statistics']['mean_trend'] for r in individual_results]\n",
    "chatgpt_means = [r['predicted_chatgpt_trend']['statistics']['mean_predicted'] for r in individual_results]\n",
    "\n",
    "x = np.arange(len(keywords))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.bar(x - width/2, google_means, width, label='Google Trends', alpha=0.8, color='#1f77b4')\n",
    "bars2 = ax1.bar(x + width/2, chatgpt_means, width, label='Predicted ChatGPT', alpha=0.8, color='#ff7f0e')\n",
    "\n",
    "ax1.set_xlabel('Keywords', fontsize=12)\n",
    "ax1.set_ylabel('Average Trend Value', fontsize=12)\n",
    "ax1.set_title('Model 3 Analysis: Keyword Performance Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(keywords, rotation=45, ha='right')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add values on bars\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                f'{height:.1f}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "# Plot 2: Confidence analysis\n",
    "confidences = [r['analysis_summary']['prediction_confidence'] for r in individual_results]\n",
    "bars3 = ax2.bar(keywords, confidences, color='#2ca02c', alpha=0.7)\n",
    "ax2.set_xlabel('Keywords', fontsize=12)\n",
    "ax2.set_ylabel('Prediction Confidence', fontsize=12)\n",
    "ax2.set_title('Prediction Confidence by Keyword', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add confidence values on bars\n",
    "for bar, conf in zip(bars3, confidences):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "            f'{conf:.3f}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "# Plot 3: Correlation analysis\n",
    "correlations = [r['analysis_summary']['trend_correlation'] for r in individual_results]\n",
    "bars4 = ax3.bar(keywords, correlations, color='#d62728', alpha=0.7)\n",
    "ax3.set_xlabel('Keywords', fontsize=12)\n",
    "ax3.set_ylabel('Trend Correlation', fontsize=12)\n",
    "ax3.set_title('Google vs ChatGPT Trend Correlation', fontsize=14, fontweight='bold')\n",
    "ax3.set_ylim(-1, 1)\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Add correlation values on bars\n",
    "for bar, corr in zip(bars4, correlations):\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "            f'{corr:.3f}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "# Plot 4: Summary metrics\n",
    "metrics = ['Google Trends', 'Predicted ChatGPT', 'Confidence', 'Correlation']\n",
    "avg_values = [\n",
    "    avg['average_google_trend'],\n",
    "    avg['average_predicted_chatgpt'],\n",
    "    avg['average_confidence'],\n",
    "    avg['average_correlation']\n",
    "]\n",
    "std_values = [\n",
    "    avg['std_google_trend'],\n",
    "    avg['std_predicted_chatgpt'],\n",
    "    avg['std_confidence'],\n",
    "    avg['std_correlation']\n",
    "]\n",
    "\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "bars5 = ax4.bar(metrics, avg_values, yerr=std_values, capsize=5, \n",
    "               color=colors, alpha=0.7)\n",
    "ax4.set_ylabel('Average Value', fontsize=12)\n",
    "ax4.set_title('Overall Performance Summary', fontsize=14, fontweight='bold')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# Add average values on bars\n",
    "for bar, avg_val in zip(bars5, avg_values):\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "            f'{avg_val:.3f}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f995d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final summary and insights\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"🎯 FINAL ANALYSIS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"📝 Original Prompt: '{result['prompt']}'\")\n",
    "print(f\" Generated Keywords: {', '.join(result['generated_keywords'])}\")\n",
    "print(f\"✅ Successfully Analyzed: {', '.join(result['successful_keywords'])}\")\n",
    "print(f\"📊 Analysis Period: June 2025\")\n",
    "print(f\" Keywords: {avg['num_keywords']}\")\n",
    "\n",
    "print(f\"\\n📈 PERFORMANCE METRICS:\")\n",
    "print(f\"   📊 Average Google Trend: {avg['average_google_trend']:.2f} ± {avg['std_google_trend']:.2f}\")\n",
    "print(f\"   🤖 Average Predicted ChatGPT: {avg['average_predicted_chatgpt']:.2f} ± {avg['std_predicted_chatgpt']:.2f}\")\n",
    "print(f\"   Average Confidence: {avg['average_confidence']:.3f} ± {avg['std_confidence']:.3f}\")\n",
    "print(f\"   📊 Average Correlation: {avg['average_correlation']:.3f} ± {avg['std_correlation']:.3f}\")\n",
    "\n",
    "# Provide insights based on the results\n",
    "print(f\"\\n KEY INSIGHTS:\")\n",
    "if avg['average_google_trend'] > 50:\n",
    "    print(f\"   High Google search interest for Model 3 related topics\")\n",
    "else:\n",
    "    print(f\"   📉 Moderate Google search interest for Model 3 related topics\")\n",
    "\n",
    "if avg['average_predicted_chatgpt'] > avg['average_google_trend']:\n",
    "    print(f\"   🤖 ChatGPT interest predicted to be higher than Google searches\")\n",
    "else:\n",
    "    print(f\"   📊 ChatGPT interest predicted to be lower than Google searches\")\n",
    "\n",
    "if avg['average_confidence'] > 0.7:\n",
    "    print(f\"   High confidence in predictions\")\n",
    "elif avg['average_confidence'] > 0.5:\n",
    "    print(f\"   ⚖️ Moderate confidence in predictions\")\n",
    "else:\n",
    "    print(f\"   ⚠️ Low confidence in predictions\")\n",
    "\n",
    "if avg['average_correlation'] > 0.5:\n",
    "    print(f\"   Strong correlation between Google and predicted ChatGPT trends\")\n",
    "elif avg['average_correlation'] > 0.2:\n",
    "    print(f\"   📊 Moderate correlation between Google and predicted ChatGPT trends\")\n",
    "else:\n",
    "    print(f\"   📉 Weak correlation between Google and predicted ChatGPT trends\")\n",
    "\n",
    "print(f\"\\n Analysis completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa16631e",
   "metadata": {},
   "source": [
    "# Trendline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dbb166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required functions\n",
    "from embeddingsKNN import promptToKeywordsAndAnalyze, loadTrainingData, createTrendlinePlot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load training data\n",
    "print(\"🔄 Loading training data...\")\n",
    "loadTrainingData()\n",
    "print(\"✅ Training data loaded successfully\")\n",
    "\n",
    "# Run inference on the prompt\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"🚀 RUNNING INFERENCE ON PROMPT: 'is the model 3 a good car?'\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Execute the analysis\n",
    "result = promptToKeywordsAndAnalyze(\n",
    "    prompt=\"is the model 3 a good car?\",\n",
    "    startDate=\"2025-06-01\",\n",
    "    endDate=\"2025-06-30\",\n",
    "    k=3,\n",
    "    weights='distance'\n",
    ")\n",
    "\n",
    "print(f\"\\n Analysis completed!\")\n",
    "print(f\"📝 Original prompt: '{result['prompt']}'\")\n",
    "print(f\" Generated keywords: {result['generated_keywords']}\")\n",
    "print(f\"✅ Successfully analyzed: {result['successful_keywords']}\")\n",
    "print(f\" Keywords processed: {result['average_result']['num_keywords']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f2809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicitly create the trendline plot to ensure it shows\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"�� CREATING TRENDLINE PLOT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Call the trendline function explicitly\n",
    "createTrendlinePlot(\n",
    "    individual_results=result['individual_results'],\n",
    "    successful_keywords=result['successful_keywords'],\n",
    "    prompt=result['prompt']\n",
    ")\n",
    "\n",
    "print(\"✅ Trendline plot created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a127a9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an additional custom trendline visualization\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"📊 CUSTOM TRENDLINE ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Extract time series data manually\n",
    "individual_results = result['individual_results']\n",
    "successful_keywords = result['successful_keywords']\n",
    "\n",
    "if individual_results:\n",
    "    # Get dates from first result\n",
    "    first_result = individual_results[0]\n",
    "    dates = [pd.to_datetime(item['date']) for item in first_result['google_trends']['data']]\n",
    "    \n",
    "    # Extract trends\n",
    "    chatgpt_trends = []\n",
    "    google_trends = []\n",
    "    \n",
    "    for result_item in individual_results:\n",
    "        chatgpt_trends.append(result_item['predicted_chatgpt_trend']['trend_values'])\n",
    "        google_trends.append(result_item['google_trends']['trend_values'])\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    chatgpt_trends = np.array(chatgpt_trends)\n",
    "    google_trends = np.array(google_trends)\n",
    "    \n",
    "    # Calculate averages\n",
    "    avg_chatgpt_trend = np.mean(chatgpt_trends, axis=0)\n",
    "    avg_google_trend = np.mean(google_trends, axis=0)\n",
    "    \n",
    "    # Create custom trendline plot\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 12))\n",
    "    \n",
    "    # Plot 1: Individual ChatGPT trends\n",
    "    colors = ['#ff6b6b', '#4ecdc4', '#45b7d1', '#96ceb4', '#feca57']\n",
    "    for i, (keyword, trend) in enumerate(zip(successful_keywords, chatgpt_trends)):\n",
    "        color = colors[i % len(colors)]\n",
    "        ax1.plot(dates, trend, color=color, alpha=0.7, linewidth=2, \n",
    "                label=f'{keyword}', linestyle='--')\n",
    "    \n",
    "    # Plot average trendline\n",
    "    ax1.plot(dates, avg_chatgpt_trend, color='red', linewidth=4, \n",
    "            label='Average Predicted ChatGPT', linestyle='-')\n",
    "    \n",
    "    ax1.set_xlabel('Date', fontsize=12)\n",
    "    ax1.set_ylabel('Predicted ChatGPT Trend Value', fontsize=12)\n",
    "    ax1.set_title('Predicted ChatGPT Trends Over Time\\nPrompt: \"is the model 3 a good car?\"', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    ax1.legend(fontsize=10)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_ylim(0, 100)\n",
    "    \n",
    "    # Format x-axis\n",
    "    ax1.xaxis.set_major_locator(plt.matplotlib.dates.DayLocator(interval=3))\n",
    "    ax1.xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%m/%d'))\n",
    "    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)\n",
    "    \n",
    "    # Plot 2: Comparison with Google Trends\n",
    "    ax2.plot(dates, avg_google_trend, color='blue', linewidth=3, \n",
    "            label='Average Google Trends', linestyle='-')\n",
    "    ax2.plot(dates, avg_chatgpt_trend, color='red', linewidth=3, \n",
    "            label='Average Predicted ChatGPT', linestyle='--')\n",
    "    \n",
    "    ax2.set_xlabel('Date', fontsize=12)\n",
    "    ax2.set_ylabel('Trend Value', fontsize=12)\n",
    "    ax2.set_title('Google Trends vs Predicted ChatGPT Trends (Average)', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    ax2.legend(fontsize=10)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_ylim(0, 100)\n",
    "    \n",
    "    # Format x-axis\n",
    "    ax2.xaxis.set_major_locator(plt.matplotlib.dates.DayLocator(interval=3))\n",
    "    ax2.xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%m/%d'))\n",
    "    plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print trendline statistics\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"TRENDLINE ANALYSIS SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Time period: {dates[0].strftime('%Y-%m-%d')} to {dates[-1].strftime('%Y-%m-%d')}\")\n",
    "    print(f\"Number of data points: {len(dates)}\")\n",
    "    print(f\"Average ChatGPT trend range: {np.min(avg_chatgpt_trend):.1f} - {np.max(avg_chatgpt_trend):.1f}\")\n",
    "    print(f\"Average Google trend range: {np.min(avg_google_trend):.1f} - {np.max(avg_google_trend):.1f}\")\n",
    "    \n",
    "    # Calculate trend direction\n",
    "    chatgpt_trend_direction = \"↗️ Increasing\" if avg_chatgpt_trend[-1] > avg_chatgpt_trend[0] else \"↘️ Decreasing\"\n",
    "    google_trend_direction = \"↗️ Increasing\" if avg_google_trend[-1] > avg_google_trend[0] else \"↘️ Decreasing\"\n",
    "    \n",
    "    print(f\"ChatGPT trend direction: {chatgpt_trend_direction}\")\n",
    "    print(f\"Google trend direction: {google_trend_direction}\")\n",
    "    \n",
    "    # Calculate volatility\n",
    "    print(f\"ChatGPT trend volatility: {np.std(avg_chatgpt_trend):.2f}\")\n",
    "    print(f\"Google trend volatility: {np.std(avg_google_trend):.2f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No individual results available for trendline analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b52915b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"🎯 FINAL ANALYSIS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "avg = result['average_result']\n",
    "print(f\"📝 Original Prompt: '{result['prompt']}'\")\n",
    "print(f\" Generated Keywords: {', '.join(result['generated_keywords'])}\")\n",
    "print(f\"✅ Successfully Analyzed: {', '.join(result['successful_keywords'])}\")\n",
    "print(f\"📊 Analysis Period: June 2025\")\n",
    "print(f\" Keywords: {avg['num_keywords']}\")\n",
    "\n",
    "print(f\"\\n📈 PERFORMANCE METRICS:\")\n",
    "print(f\"   📊 Average Google Trend: {avg['average_google_trend']:.2f} ± {avg['std_google_trend']:.2f}\")\n",
    "print(f\"   🤖 Average Predicted ChatGPT: {avg['average_predicted_chatgpt']:.2f} ± {avg['std_predicted_chatgpt']:.2f}\")\n",
    "print(f\"   Average Confidence: {avg['average_confidence']:.3f} ± {avg['std_confidence']:.3f}\")\n",
    "print(f\"   📊 Average Correlation: {avg['average_correlation']:.3f} ± {avg['std_correlation']:.3f}\")\n",
    "\n",
    "print(f\"\\n Analysis completed successfully!\")\n",
    "print(f\"�� You should now see the trendline plots showing how ChatGPT trends evolve over time!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peec-hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
